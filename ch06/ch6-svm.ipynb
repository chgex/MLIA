{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# ch6 支持向量机\n",
    "\n",
    "- 支持向量机\n",
    "\n",
    "- 使用SMO进行优化\n",
    "\n",
    "- 使用核函数，对数据进行空间转换\n",
    "\n",
    "support vector machine中的“机”是因为：原始分类器，不加修改只能用于处理让二类问题，所以叫做机。\n",
    "\n",
    "## 6-1 SVM\n",
    "\n",
    "优点：泛化强，计算开销小；\n",
    "\n",
    "缺点：对参数和核函数敏感。\n",
    "\n",
    "适用：数值型，标称型\n",
    "\n",
    "**SVM**\n",
    "\n",
    "将数据集分割开来的直线称为分割超平面，该平面有N-1维（数据集是N维）。\n",
    "\n",
    "数据点距离超平面越远，分割效果越好。\n",
    "\n",
    "希望找到距离超平面最近的点（这些点又叫做支持向量），确保它们距离超平面的距离（也叫做间隔）尽可能的远。\n",
    "\n",
    "svm优化目标：最大化支持向量到超平面的距离。\n",
    "\n",
    "**寻找最大间隔**\n",
    "\n",
    "超平面格式为：$w^Tx+b$，计算数据点A到该超平面的距离，即计算点到分割面的法线或垂线的长度：\n",
    "$$\n",
    "\\frac{|w^TA+b|}{|w|}\n",
    "$$\n",
    "\n",
    "**优化问题**\n",
    "\n",
    "使用单位跃阶函数f，令$u=w^Tx+b$，则u<0时f(u)=-1，反之则为1。\n",
    "\n",
    "分类器接受数据输入，则输出一个类比标签-1或者1.\n",
    "\n",
    "为什么要用-1和1，而不是0和1，是因为在计算间隔（数据点到分割超平面的距离）时，是通过$label*(w^Tx+b$计算的。\n",
    "\n",
    "如果数据点为+1类，而且距离超平面极远，则$w^Tx+b$是极大的正数，同时$label* w^Tx+b$也是极大的正数。\n",
    "\n",
    "如果数据点为-1类，而且距离超平面极远，则$w^Tx+b$是极大的负数，同时$label* w^Tx+b$将是极大的正数。\n",
    "\n",
    "于是就达到了不同类别下，相同的距离度量方式。\n",
    "\n",
    "于是优化目标变为：先寻找具有最小间隔的数据点（这些点也叫做支持向量），然后按照这些点，来寻找出w和b。\n",
    "\n",
    "以间隔最大为优化目标，来寻找支持向量，使用以下优化函数：\n",
    "\n",
    "$$\n",
    "arg\\max_{w,b}\\{ \\min_n(label * (w^Tx+b)) *\\frac{1}{||w||} \\}\n",
    "$$\n",
    "\n",
    "对于上式，令所有支持向量的$label* w^Tx+b = 1$，则距离越远的点$label* w^Tx+b$值就越大。\n",
    "\n",
    "于是优化函数就转换为约束条件$label* w^Tx+b \\leq 1 $下的优化问题：只需要计算$||w||^{-1}$最大值，来得到最终解。\n",
    "\n",
    "于是优化目标函数变为：\n",
    "\n",
    "$$\n",
    "\\max_{\\alpha}[\\sum_{i=1}^{m}\\alpha - \\frac{1}{2}\\sum_{i,j=1}^{m}label^{(i)}*label^{(j)}*{\\alpha}^i*{\\alpha^j}<x^{(i)},y^{(i)}>]\n",
    "$$\n",
    "\n",
    "约束条件为：\n",
    "\n",
    "$$\n",
    "C \\leq \\alpha \\leq 0,\\sum_{i=1}^{m}\\alpha^i*label^{(i)}=0\n",
    "$$\n",
    "\n",
    "常数C为松驰变量，控制最大化间隔和保证大部分点的函数间隔($label* (w^Tx+b)) *\\frac{1}{||w||}$为函数间隔)小于1.0，这两个目标的权重。\n",
    "\n",
    "SVM主要工作就是找到这些$\\alpha$\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## SMO优化算法\n",
    "\n",
    "SMP算法目标就是求出一系列$\\alpha$和b，根据$\\alpha$就可以计算出权重向量w。得到超平面。\n",
    "\n",
    "简化版SOM优化算法"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadData(filename):\n",
    "    # 加载数据\n",
    "    dataArr=[];labelArr=[]\n",
    "    fr=open(filename)\n",
    "    for line in fr.readlines():\n",
    "        lineArr=line.strip().split('\\t')\n",
    "        dataArr.append([float(lineArr[0]),float(lineArr[1])])\n",
    "        labelArr.append(float(lineArr[2]))\n",
    "    return dataArr,labelArr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def selectJrand(i,m):\n",
    "    # 第i个alpha的下标，m是alpha的总数\n",
    "    j=i\n",
    "    while (j==i):\n",
    "        j=int(np.random.uniform(0,m))\n",
    "    return j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clipAlpha(alpha,H,L):\n",
    "    # 调整大于或小于alpha的值\n",
    "    if alpha>H:\n",
    "        alpha=H\n",
    "    if alpha<L:\n",
    "        alpha=L\n",
    "    return alpha"
   ]
  },
  {
   "source": [
    "简化版的SMO算法伪代码：\n",
    "\n",
    "```\n",
    "创建alpha向量，并初始化为0向量\n",
    "开始迭代：\n",
    "    遍历数据集中每一个向量：\n",
    "        如果该数据向量可以被优化：\n",
    "            随机选择另一个数据向量\n",
    "            同时优化这两个数据向量\n",
    "            如果这两个数据向量都不能被优化，则退出内循环\n",
    "        如果没有数据向量可被优化，则下一次迭代\n",
    "```\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def smoSimple(dataArr,labelArr,C,toler,maxIter):\n",
    "    # arg:数据集，标签集，松弛变量，容错率，最大迭代次数\n",
    "    # return: 模型常数b,拉格朗日乘子alpha\n",
    "    \n",
    "    # 将数据集转为向量\n",
    "    dataMat=np.mat(dataArr)\n",
    "    labelMat=np.mat(labelArr).T\n",
    "    # 数据维度\n",
    "    m,n=np.shape(dataMat)\n",
    "    # 初始化alpha和b\n",
    "    b=0\n",
    "    alphas=np.zeros((m,1))\n",
    "    \n",
    "    # 迭代\n",
    "    iter=0\n",
    "    # for iter in range(maxIter):\n",
    "    while(iter<maxIter):\n",
    "        alphaPairsChanged=0\n",
    "        # 遍历数据集\n",
    "        for i in range(m):\n",
    "            # 预测的结果y[i]=w^T*x[i]+b，其中W=\\sum_{i=1}^{m} alpha^i * label^i\n",
    "            # np.multiply(m*1,m*1)=m*1,等价于(m*1)*(m*1)\n",
    "            # W.T为1*m\n",
    "            W=np.multiply(alphas,labelMat)\n",
    "            # m*1\n",
    "            # Xi=np.multiply(dataMat,dataMat[i,:].T)\n",
    "            Xi=np.dot(dataMat, dataMat[i,:].T)\n",
    "            print(\"np.shape(Xi)\",np.shape(Xi))\n",
    "            # 预测值\n",
    "            # 1*1\n",
    "            fxi=np.dot(W.T,Xi)\n",
    "            fxi=np.float(fxi)\n",
    "            # 计算误差\n",
    "            Ei=fxi-float(labelMat[i])\n",
    "            \n",
    "            # 判断是否满足优化条件\n",
    "            if ((labelMat[i]*Ei<-toler) and (alphas[i]<C)) or ((labelMat[i]*Ei > toler) and (alphas[i] > 0)):\n",
    "                # 则随机选择另一个点\n",
    "                j=selectJ(i,m)\n",
    "                # 预测\n",
    "                Xj=np.dot(dataMat,dataMat[j,:].T)\n",
    "                # 预测值\n",
    "                fxj=np.dot(W.T,Xj)\n",
    "                fxj=float(fxj)\n",
    "                # 计算误差\n",
    "                Ej=fxj-float(labelMat[j])\n",
    "\n",
    "                # 记录原alpha的值\n",
    "                alphaIold = alphas[i].copy()\n",
    "                alphaJold = alphas[j].copy()\n",
    "\n",
    "                # L和H用于将alphas[j]调整到0-C之间。\n",
    "                # 如果L==H，就不做任何改变，直接执行continue语句\n",
    "                # labelMat[i] != labelMat[j] 表示异侧，就相减，否则是同侧，就相加。\n",
    "                if (labelMat[i] != labelMat[j]):\n",
    "                    L = max(0, alphas[j] - alphas[i])\n",
    "                    H = min(C, C + alphas[j] - alphas[i])\n",
    "                else:\n",
    "                    L = max(0, alphas[j] + alphas[i] - C)\n",
    "                    H = min(C, alphas[j] + alphas[i])\n",
    "                # 如果相同，就没法优化了\n",
    "                if L == H:\n",
    "                    print(\"L==H\")\n",
    "                    continue\n",
    "                # eta是alphas[j]的最优修改量，如果eta==0，需要退出for循环的当前迭代过程\n",
    "                # 参考《统计学习方法》李航-P125~P128<序列最小最优化算法>\n",
    "                eta = 2.0 * np.dot(dataMat[i, :],dataMat[j, :].T) - np.dot(dataMat[i, :],dataMat[i, :].T) - np.dot(dataMat[j, :],dataMat[j, :].T)\n",
    "                if eta >= 0:\n",
    "                    print(\"eta>=0\")\n",
    "                    continue\n",
    "                \n",
    "                # 计算出一个新的alphas[j]值\n",
    "                alphas[j] =alphas[j]- labelMat[j]*(Ei - Ej)/eta\n",
    "                # 并使用辅助函数，以及L和H对其进行调整\n",
    "                alphas[j] = clipAlpha(alphas[j], H, L)\n",
    "                # 检查alpha[j]是否只是轻微的改变，如果是的话，就退出for循环。\n",
    "                if (abs(alphas[j] - alphaJold) < 0.00001):\n",
    "                    print(\"j not moving enough\")\n",
    "                    continue\n",
    "                \n",
    "                # alphas[i]和alphas[j]同样进行改变，\n",
    "                # 虽然改变的大小一样，但是改变的方向正好相反\n",
    "                alphas[i] =alphas[i] + labelMat[j]*labelMat[i]*(alphaJold - alphas[j])\n",
    "                # 在对alpha[i], alpha[j] 进行优化之后，给这两个alpha值设置一个常数b。\n",
    "                # w= Σ[1~n] ai*yi*xi => b = yj- Σ[1~n] ai*yi(xi*xj)\n",
    "                # 所以:   b1 - b = (y1-y) - Σ[1~n] yi*(a1-a)*(xi*x1)\n",
    "                # 为什么减2遍？ 因为是 减去Σ[1~n]，正好2个变量i和j，所以减2遍\n",
    "                b1 = b - Ei- labelMat[i]*(alphas[i]-alphaIold)*np.dot(dataMat[i, :],dataMat[i, :].T) - labelMat[j]*(alphas[j]-alphaJold)*np.dot(dataMat[i, :],dataMat[j, :].T)\n",
    "                b2 = b - Ej- labelMat[i]*(alphas[i]-alphaIold)*np.dot(dataMat[i, :],dataMat[j, :].T) - labelMat[j]*(alphas[j]-alphaJold)*np.dot(dataMat[j, :],dataMat[j, :].T)\n",
    "                if (0 < alphas[i]) and (C > alphas[i]):\n",
    "                    b = b1\n",
    "                elif (0 < alphas[j]) and (C > alphas[j]):\n",
    "                    b = b2\n",
    "                else:\n",
    "                    b = (b1 + b2)/2.0\n",
    "                alphaPairsChanged += 1\n",
    "                print(\"iter: %d i:%d, pairs changed %d\" % (iter, i, alphaPairsChanged))\n",
    "        if (alphaPairsChanged == 0):\n",
    "            iter += 1\n",
    "        else:\n",
    "            iter = 0\n",
    "        print(\"iteration number: %d\" % iter)\n",
    "    return b,alphas"
   ]
  },
  {
   "source": [
    "# test\n",
    "dataArr,labelArr=loadData('./testSet.txt')\n",
    "print(labelArr[:2])\n",
    "b,alphas=smoSimple(dataArr,labelArr,0.6,0.001,40)"
   ],
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   }
  },
  {
   "source": [
    "print(b)\n",
    "alphas[alphas>0]"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# 支持向量\n",
    "for i in range(100):\n",
    "    if alphas[i]>0.0:\n",
    "        print(dataArr[i],labelArr[i])"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 完整版的platt SMO算法\n",
    "\n",
    "。。。"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "class optS:\n",
    "    def __init__(self,dataArr,labelArr,C,toler):\n",
    "        self.dataMat=np.mat(dataArr)\n",
    "        self.labelMat=np.mat(labelArr)\n",
    "        self.C=C\n",
    "        self.tol=toler\n",
    "        self.m,self.n=np.shape(dataArr)\n",
    "        self.alphas=np.zeros((self.m,1))\n",
    "        self.b=0\n",
    "        # 是否有效，实际的E值\n",
    "        self.cache=np.zeros((self.m,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcEk(oS:optS,i:int):\n",
    "    # 给定alpha下计算E\n",
    "    # W^T\n",
    "    W=np.multiply(oS.alphas,oS.labelMat)\n",
    "    # m*1\n",
    "    # Xi=np.multiply(dataMat,dataMat[i,:].T)\n",
    "    Xi=np.dot(oS.dataMat, oS.dataMat[i,:].T)\n",
    "    # 预测值 1*1\n",
    "    fxi=np.dot(W.T,Xi)+oS.b\n",
    "    # 计算误差\n",
    "    Ei=fxi-float(oS.labelMat[i])\n",
    "    # 返回误差\n",
    "    return Ei"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def selectJ(i, oS, Ei):  # this is the second choice -heurstic, and calcs Ej\n",
    "    \"\"\"selectJ（返回最优的j和Ej）\n",
    "    内循环的启发式方法。\n",
    "    选择第二个(内循环)alpha的alpha值\n",
    "    这里的目标是选择合适的第二个alpha值以保证每次优化中采用最大步长。\n",
    "    该函数的误差与第一个alpha值Ei和下标i有关。\n",
    "    Args:\n",
    "        i   具体的第i一行\n",
    "        oS  optStruct对象\n",
    "        Ei  预测结果与真实结果比对，计算误差Ei\n",
    "    Returns:\n",
    "        j  随机选出的第j一行\n",
    "        Ej 预测结果与真实结果比对，计算误差Ej\n",
    "    \"\"\"\n",
    "    maxK = -1\n",
    "    maxDeltaE = 0\n",
    "    Ej = 0\n",
    "    # 首先将输入值Ei在缓存中设置成为有效的。这里的有效意味着它已经计算好了。\n",
    "    oS.cache[i] = [1, Ei]\n",
    "\n",
    "    # print 'oS.eCache[%s]=%s' % (i, oS.eCache[i])\n",
    "    # print 'oS.eCache[:, 0].A=%s' % oS.eCache[:, 0].A.T\n",
    "    # \"\"\"\n",
    "    # # 返回非0的: 行列值\n",
    "    # nonzero(oS.eCache[:, 0].A)= (\n",
    "    #     行:  array([ 0,  2,  4,  5,  8, 10, 17, 18, 20, 21, 23, 25, 26, 29, 30, 39, 46,52, 54, 55, 62, 69, 70, 76, 79, 82, 94, 97]), \n",
    "    #     列:  array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,0, 0, 0, 0, 0])\n",
    "    # )\n",
    "    # \"\"\"\n",
    "    # print 'nonzero(oS.eCache[:, 0].A)=', nonzero(oS.eCache[:, 0].A)\n",
    "    # # 取行的list\n",
    "    # print 'nonzero(oS.eCache[:, 0].A)[0]=', nonzero(oS.eCache[:, 0].A)[0]\n",
    "    # 非零E值的行的list列表，所对应的alpha值\n",
    "    validEcacheList = np.nonzero(oS.cache[:, 0].T)[0]\n",
    "    if (len(validEcacheList)) > 1:\n",
    "        for k in validEcacheList:  # 在所有的值上进行循环，并选择其中使得改变最大的那个值\n",
    "            if k == i:\n",
    "                continue  # don't calc for i, waste of time\n",
    "\n",
    "            # 求 Ek误差: 预测值-真实值的差\n",
    "            Ek = calcEk(oS, k)\n",
    "            deltaE = abs(Ei - Ek)\n",
    "            if (deltaE > maxDeltaE):\n",
    "                maxK = k\n",
    "                maxDeltaE = deltaE\n",
    "                Ej = Ek\n",
    "        return maxK, Ej\n",
    "    else:  # 如果是第一次循环，则随机选择一个alpha值\n",
    "        j = selectJrand(i, oS.m)\n",
    "\n",
    "        # 求 Ek误差: 预测值-真实值的差\n",
    "        Ej = calcEk(oS, j)\n",
    "    return j, Ej"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def updateEk(oS, k):  # after any alpha has changed update the new value in the cache\n",
    "    # 计算误差并存入缓存\n",
    "    \"\"\"updateEk（计算误差值并存入缓存中。）\n",
    "    在对alpha值进行优化之后会用到这个值。\n",
    "    Args:\n",
    "        oS  optStruct对象\n",
    "        k   某一列的行号\n",
    "    \"\"\"\n",
    "    # 求 误差: 预测值-真实值的差\n",
    "    Ek = calcEk(oS, k)\n",
    "    oS.cache[k] = [1, Ek]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def innerL(i, oS):\n",
    "    \"\"\"innerL\n",
    "    内循环代码\n",
    "    Args:\n",
    "        i   具体的某一行\n",
    "        oS  optStruct对象\n",
    "    Returns:\n",
    "        0   找不到最优的值\n",
    "        1   找到了最优的值，并且oS.Cache到缓存中\n",
    "    \"\"\"\n",
    "\n",
    "    # 求 Ek误差: 预测值-真实值的差\n",
    "    Ei = calcEk(oS, i)\n",
    "\n",
    "    # 约束条件 (KKT条件是解决最优化问题的时用到的一种方法。我们这里提到的最优化问题通常是指对于给定的某一函数，求其在指定作用域上的全局最小值)\n",
    "    # 0<=alphas[i]<=C，但由于0和C是边界值，我们无法进行优化，因为需要增加一个alphas和降低一个alphas。\n",
    "    # 表示发生错误的概率: labelMat[i]*Ei 如果超出了 toler， 才需要优化。至于正负号，我们考虑绝对值就对了。\n",
    "    if ((oS.labelMat[i] * Ei < -oS.tol) and (oS.alphas[i] < oS.C)) or ((oS.labelMat[i] * Ei > oS.tol) and (oS.alphas[i] > 0)):\n",
    "        # 选择最大的误差对应的j进行优化。效果更明显\n",
    "        j, Ej = selectJ(i, oS, Ei)\n",
    "        alphaIold = oS.alphas[i].copy()\n",
    "        alphaJold = oS.alphas[j].copy()\n",
    "\n",
    "        # L和H用于将alphas[j]调整到0-C之间。如果L==H，就不做任何改变，直接return 0\n",
    "        if (oS.labelMat[i] != oS.labelMat[j]):\n",
    "            L = max(0, oS.alphas[j] - oS.alphas[i])\n",
    "            H = min(oS.C, oS.C + oS.alphas[j] - oS.alphas[i])\n",
    "        else:\n",
    "            L = max(0, oS.alphas[j] + oS.alphas[i] - oS.C)\n",
    "            H = min(oS.C, oS.alphas[j] + oS.alphas[i])\n",
    "        if L == H:\n",
    "            print(\"L==H\")\n",
    "            return 0\n",
    "\n",
    "        # eta是alphas[j]的最优修改量，如果eta==0，需要退出for循环的当前迭代过程\n",
    "        # 参考《统计学习方法》李航-P125~P128<序列最小最优化算法>\n",
    "        eta = 2.0 * oS.dataMat[i, :] * oS.dataMat[j, :].T - oS.dataMat[i, :] * oS.dataMat[i, :].T - oS.dataMat[j, :] * oS.dataMat[j, :].T\n",
    "        if eta >= 0:\n",
    "            print(\"eta>=0\")\n",
    "            return 0\n",
    "\n",
    "        # 计算出一个新的alphas[j]值\n",
    "        oS.alphas[j] =oS.alphas[j]- oS.labelMat[j] * (Ei - Ej) / eta\n",
    "        # 并使用辅助函数，以及L和H对其进行调整\n",
    "        oS.alphas[j] = clipAlpha(oS.alphas[j], H, L)\n",
    "        # 更新误差缓存\n",
    "        updateEk(oS, j)\n",
    "\n",
    "        # 检查alpha[j]是否只是轻微的改变，如果是的话，就退出for循环。\n",
    "        if (abs(oS.alphas[j] - alphaJold) < 0.00001):\n",
    "            print(\"j not moving enough\")\n",
    "            return 0\n",
    "\n",
    "        # 然后alphas[i]和alphas[j]同样进行改变，虽然改变的大小一样，但是改变的方向正好相反\n",
    "        oS.alphas[i] =oS.alphas[i] + oS.labelMat[j] * oS.labelMat[i] * (alphaJold - oS.alphas[j])\n",
    "        # 更新误差缓存\n",
    "        updateEk(oS, i)\n",
    "\n",
    "        # 在对alpha[i], alpha[j] 进行优化之后，给这两个alpha值设置一个常数b。\n",
    "        # w= Σ[1~n] ai*yi*xi => b = yj Σ[1~n] ai*yi(xi*xj)\n",
    "        # 所以:   b1 - b = (y1-y) - Σ[1~n] yi*(a1-a)*(xi*x1)\n",
    "        # 为什么减2遍？ 因为是 减去Σ[1~n]，正好2个变量i和j，所以减2遍\n",
    "        b1 = oS.b - Ei - oS.labelMat[i] * (oS.alphas[i] - alphaIold) * oS.dataMat[i, :] * oS.dataMat[i, :].T - oS.labelMat[j] * (oS.alphas[j] - alphaJold) * oS.dataMat[i, :] * oS.dataMat[j, :].T\n",
    "        b2 = oS.b - Ej - oS.labelMat[i] * (oS.alphas[i] - alphaIold) * oS.dataMat[i, :] * oS.dataMat[j, :].T - oS.labelMat[j] * (oS.alphas[j] - alphaJold) * oS.dataMat[j, :] * oS.dataMat[j, :].T\n",
    "        if (0 < oS.alphas[i]) and (oS.C > oS.alphas[i]):\n",
    "            oS.b = b1\n",
    "        elif (0 < oS.alphas[j]) and (oS.C > oS.alphas[j]):\n",
    "            oS.b = b2\n",
    "        else:\n",
    "            oS.b = (b1 + b2) / 2.0\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smoP(dataMatIn, classLabels, C, toler, maxIter):\n",
    "    \"\"\"\n",
    "    完整SMO算法外循环，与smoSimple有些类似，但这里的循环退出条件更多一些\n",
    "    Args:\n",
    "        dataMatIn    数据集\n",
    "        classLabels  类别标签\n",
    "        C   松弛变量(常量值)，允许有些数据点可以处于分隔面的错误一侧。\n",
    "            控制最大化间隔和保证大部分的函数间隔小于1.0这两个目标的权重。\n",
    "            可以通过调节该参数达到不同的结果。\n",
    "        toler   容错率\n",
    "        maxIter 退出前最大的循环次数\n",
    "    Returns:\n",
    "        b       模型的常量值\n",
    "        alphas  拉格朗日乘子\n",
    "    \"\"\"\n",
    "\n",
    "    # 创建一个 optStruct 对象\n",
    "    oS = optStruct(np.mat(dataMatIn), np.mat(classLabels).transpose(), C, toler)\n",
    "    iter = 0\n",
    "    entireSet = True\n",
    "    alphaPairsChanged = 0\n",
    "\n",
    "    # 循环遍历: 循环maxIter次 并且 （alphaPairsChanged存在可以改变 or 所有行遍历一遍）\n",
    "    # 循环迭代结束 或者 循环遍历所有alpha后，alphaPairs还是没变化\n",
    "    while (iter < maxIter) and ((alphaPairsChanged > 0) or (entireSet)):\n",
    "        alphaPairsChanged = 0\n",
    "\n",
    "        #  当entireSet=true or 非边界alpha对没有了；就开始寻找 alpha对，然后决定是否要进行else。\n",
    "        if entireSet:\n",
    "            # 在数据集上遍历所有可能的alpha\n",
    "            for i in range(oS.m):\n",
    "                # 是否存在alpha对，存在就+1\n",
    "                alphaPairsChanged += innerL(i, oS)\n",
    "                print(\"fullSet, iter: %d i:%d, pairs changed %d\" % (iter, i, alphaPairsChanged))\n",
    "            iter += 1\n",
    "        # 对已存在 alpha对，选出非边界的alpha值，进行优化。\n",
    "        else:\n",
    "            # 遍历所有的非边界alpha值，也就是不在边界0或C上的值。\n",
    "            nonBoundIs = np.nonzero((oS.alphas.T > 0) * (oS.alphas.T < C))[0]\n",
    "            for i in nonBoundIs:\n",
    "                alphaPairsChanged += innerL(i, oS)\n",
    "                print(\"non-bound, iter: %d i:%d, pairs changed %d\" % (iter, i, alphaPairsChanged))\n",
    "            iter += 1\n",
    "\n",
    "        # 如果找到alpha对，就优化非边界alpha值，否则，就重新进行寻找，如果寻找一遍 遍历所有的行还是没找到，就退出循环。\n",
    "        if entireSet:\n",
    "            entireSet = False  # toggle entire set loop\n",
    "        elif (alphaPairsChanged == 0):\n",
    "            entireSet = True\n",
    "        print(\"iteration number: %d\" % iter)\n",
    "    return oS.b, oS.alphas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "L==H\nfullSet, iter: 0 i:0, pairs changed 0\nL==H\nfullSet, iter: 0 i:1, pairs changed 0\nfullSet, iter: 0 i:2, pairs changed 1\nL==H\nfullSet, iter: 0 i:3, pairs changed 1\nfullSet, iter: 0 i:4, pairs changed 2\nfullSet, iter: 0 i:5, pairs changed 2\nfullSet, iter: 0 i:6, pairs changed 2\nj not moving enough\nfullSet, iter: 0 i:7, pairs changed 2\nL==H\nfullSet, iter: 0 i:8, pairs changed 2\nfullSet, iter: 0 i:9, pairs changed 2\nL==H\nfullSet, iter: 0 i:10, pairs changed 2\nL==H\nfullSet, iter: 0 i:11, pairs changed 2\nL==H\nfullSet, iter: 0 i:12, pairs changed 2\nfullSet, iter: 0 i:13, pairs changed 2\nL==H\nfullSet, iter: 0 i:14, pairs changed 2\nfullSet, iter: 0 i:15, pairs changed 2\nfullSet, iter: 0 i:16, pairs changed 2\nL==H\nfullSet, iter: 0 i:17, pairs changed 2\nfullSet, iter: 0 i:18, pairs changed 3\nfullSet, iter: 0 i:19, pairs changed 3\nfullSet, iter: 0 i:20, pairs changed 3\nfullSet, iter: 0 i:21, pairs changed 3\nj not moving enough\nfullSet, iter: 0 i:22, pairs changed 3\nL==H\nfullSet, iter: 0 i:23, pairs changed 3\nL==H\nfullSet, iter: 0 i:24, pairs changed 3\nfullSet, iter: 0 i:25, pairs changed 4\nj not moving enough\nfullSet, iter: 0 i:26, pairs changed 4\nfullSet, iter: 0 i:27, pairs changed 4\nfullSet, iter: 0 i:28, pairs changed 4\nL==H\nfullSet, iter: 0 i:29, pairs changed 4\nfullSet, iter: 0 i:30, pairs changed 4\nfullSet, iter: 0 i:31, pairs changed 4\nfullSet, iter: 0 i:32, pairs changed 4\nfullSet, iter: 0 i:33, pairs changed 4\nfullSet, iter: 0 i:34, pairs changed 4\nfullSet, iter: 0 i:35, pairs changed 4\nfullSet, iter: 0 i:36, pairs changed 4\nfullSet, iter: 0 i:37, pairs changed 4\nfullSet, iter: 0 i:38, pairs changed 4\nfullSet, iter: 0 i:39, pairs changed 4\nfullSet, iter: 0 i:40, pairs changed 4\nfullSet, iter: 0 i:41, pairs changed 4\nfullSet, iter: 0 i:42, pairs changed 4\nfullSet, iter: 0 i:43, pairs changed 4\nfullSet, iter: 0 i:44, pairs changed 4\nfullSet, iter: 0 i:45, pairs changed 4\nfullSet, iter: 0 i:46, pairs changed 5\nfullSet, iter: 0 i:47, pairs changed 5\nfullSet, iter: 0 i:48, pairs changed 5\nfullSet, iter: 0 i:49, pairs changed 5\nfullSet, iter: 0 i:50, pairs changed 5\nfullSet, iter: 0 i:51, pairs changed 5\nL==H\nfullSet, iter: 0 i:52, pairs changed 5\nfullSet, iter: 0 i:53, pairs changed 5\nL==H\nfullSet, iter: 0 i:54, pairs changed 5\nL==H\nfullSet, iter: 0 i:55, pairs changed 5\nfullSet, iter: 0 i:56, pairs changed 5\nfullSet, iter: 0 i:57, pairs changed 5\nfullSet, iter: 0 i:58, pairs changed 5\nfullSet, iter: 0 i:59, pairs changed 5\nfullSet, iter: 0 i:60, pairs changed 5\nfullSet, iter: 0 i:61, pairs changed 5\nfullSet, iter: 0 i:62, pairs changed 5\nfullSet, iter: 0 i:63, pairs changed 5\nfullSet, iter: 0 i:64, pairs changed 5\nfullSet, iter: 0 i:65, pairs changed 5\nfullSet, iter: 0 i:66, pairs changed 5\nfullSet, iter: 0 i:67, pairs changed 5\nfullSet, iter: 0 i:68, pairs changed 5\nL==H\nfullSet, iter: 0 i:69, pairs changed 5\nfullSet, iter: 0 i:70, pairs changed 5\nfullSet, iter: 0 i:71, pairs changed 5\nfullSet, iter: 0 i:72, pairs changed 5\nfullSet, iter: 0 i:73, pairs changed 5\nfullSet, iter: 0 i:74, pairs changed 5\nfullSet, iter: 0 i:75, pairs changed 5\nfullSet, iter: 0 i:76, pairs changed 5\nfullSet, iter: 0 i:77, pairs changed 5\nfullSet, iter: 0 i:78, pairs changed 5\nfullSet, iter: 0 i:79, pairs changed 5\nfullSet, iter: 0 i:80, pairs changed 5\nfullSet, iter: 0 i:81, pairs changed 5\nfullSet, iter: 0 i:82, pairs changed 5\nfullSet, iter: 0 i:83, pairs changed 5\nfullSet, iter: 0 i:84, pairs changed 5\nfullSet, iter: 0 i:85, pairs changed 5\nfullSet, iter: 0 i:86, pairs changed 5\nfullSet, iter: 0 i:87, pairs changed 5\nfullSet, iter: 0 i:88, pairs changed 5\nfullSet, iter: 0 i:89, pairs changed 5\nfullSet, iter: 0 i:90, pairs changed 5\nfullSet, iter: 0 i:91, pairs changed 5\nfullSet, iter: 0 i:92, pairs changed 5\nfullSet, iter: 0 i:93, pairs changed 5\nfullSet, iter: 0 i:94, pairs changed 6\nfullSet, iter: 0 i:95, pairs changed 6\nfullSet, iter: 0 i:96, pairs changed 6\nj not moving enough\nfullSet, iter: 0 i:97, pairs changed 6\nfullSet, iter: 0 i:98, pairs changed 6\nfullSet, iter: 0 i:99, pairs changed 6\niteration number: 1\nj not moving enough\nnon-bound, iter: 1 i:0, pairs changed 0\nj not moving enough\nnon-bound, iter: 1 i:0, pairs changed 0\nj not moving enough\nnon-bound, iter: 1 i:0, pairs changed 0\nj not moving enough\nnon-bound, iter: 1 i:0, pairs changed 0\nj not moving enough\nnon-bound, iter: 1 i:0, pairs changed 0\nj not moving enough\nnon-bound, iter: 1 i:0, pairs changed 0\nj not moving enough\nnon-bound, iter: 1 i:0, pairs changed 0\nj not moving enough\nnon-bound, iter: 1 i:0, pairs changed 0\nj not moving enough\nnon-bound, iter: 1 i:0, pairs changed 0\niteration number: 2\nj not moving enough\nfullSet, iter: 2 i:0, pairs changed 0\nfullSet, iter: 2 i:1, pairs changed 0\nfullSet, iter: 2 i:2, pairs changed 0\nj not moving enough\nfullSet, iter: 2 i:3, pairs changed 0\nj not moving enough\nfullSet, iter: 2 i:4, pairs changed 0\nfullSet, iter: 2 i:5, pairs changed 0\nfullSet, iter: 2 i:6, pairs changed 0\nfullSet, iter: 2 i:7, pairs changed 0\nj not moving enough\nfullSet, iter: 2 i:8, pairs changed 0\nfullSet, iter: 2 i:9, pairs changed 0\nj not moving enough\nfullSet, iter: 2 i:10, pairs changed 0\nfullSet, iter: 2 i:11, pairs changed 0\nfullSet, iter: 2 i:12, pairs changed 0\nfullSet, iter: 2 i:13, pairs changed 0\nfullSet, iter: 2 i:14, pairs changed 0\nfullSet, iter: 2 i:15, pairs changed 0\nfullSet, iter: 2 i:16, pairs changed 0\nj not moving enough\nfullSet, iter: 2 i:17, pairs changed 0\nj not moving enough\nfullSet, iter: 2 i:18, pairs changed 0\nfullSet, iter: 2 i:19, pairs changed 0\nfullSet, iter: 2 i:20, pairs changed 0\nfullSet, iter: 2 i:21, pairs changed 0\nfullSet, iter: 2 i:22, pairs changed 0\nL==H\nfullSet, iter: 2 i:23, pairs changed 0\nj not moving enough\nfullSet, iter: 2 i:24, pairs changed 0\nj not moving enough\nfullSet, iter: 2 i:25, pairs changed 0\nfullSet, iter: 2 i:26, pairs changed 0\nfullSet, iter: 2 i:27, pairs changed 0\nfullSet, iter: 2 i:28, pairs changed 0\nL==H\nfullSet, iter: 2 i:29, pairs changed 0\nj not moving enough\nfullSet, iter: 2 i:30, pairs changed 0\nfullSet, iter: 2 i:31, pairs changed 0\nfullSet, iter: 2 i:32, pairs changed 0\nfullSet, iter: 2 i:33, pairs changed 0\nfullSet, iter: 2 i:34, pairs changed 0\nfullSet, iter: 2 i:35, pairs changed 0\nfullSet, iter: 2 i:36, pairs changed 0\nfullSet, iter: 2 i:37, pairs changed 0\nfullSet, iter: 2 i:38, pairs changed 0\nfullSet, iter: 2 i:39, pairs changed 0\nfullSet, iter: 2 i:40, pairs changed 0\nfullSet, iter: 2 i:41, pairs changed 0\nfullSet, iter: 2 i:42, pairs changed 0\nfullSet, iter: 2 i:43, pairs changed 0\nfullSet, iter: 2 i:44, pairs changed 0\nfullSet, iter: 2 i:45, pairs changed 0\nj not moving enough\nfullSet, iter: 2 i:46, pairs changed 0\nfullSet, iter: 2 i:47, pairs changed 0\nfullSet, iter: 2 i:48, pairs changed 0\nfullSet, iter: 2 i:49, pairs changed 0\nfullSet, iter: 2 i:50, pairs changed 0\nfullSet, iter: 2 i:51, pairs changed 0\nL==H\nfullSet, iter: 2 i:52, pairs changed 0\nfullSet, iter: 2 i:53, pairs changed 0\nL==H\nfullSet, iter: 2 i:54, pairs changed 0\nfullSet, iter: 2 i:55, pairs changed 0\nfullSet, iter: 2 i:56, pairs changed 0\nfullSet, iter: 2 i:57, pairs changed 0\nfullSet, iter: 2 i:58, pairs changed 0\nfullSet, iter: 2 i:59, pairs changed 0\nfullSet, iter: 2 i:60, pairs changed 0\nfullSet, iter: 2 i:61, pairs changed 0\nfullSet, iter: 2 i:62, pairs changed 0\nfullSet, iter: 2 i:63, pairs changed 0\nfullSet, iter: 2 i:64, pairs changed 0\nfullSet, iter: 2 i:65, pairs changed 0\nfullSet, iter: 2 i:66, pairs changed 0\nfullSet, iter: 2 i:67, pairs changed 0\nfullSet, iter: 2 i:68, pairs changed 0\nfullSet, iter: 2 i:69, pairs changed 0\nfullSet, iter: 2 i:70, pairs changed 0\nfullSet, iter: 2 i:71, pairs changed 0\nfullSet, iter: 2 i:72, pairs changed 0\nfullSet, iter: 2 i:73, pairs changed 0\nfullSet, iter: 2 i:74, pairs changed 0\nfullSet, iter: 2 i:75, pairs changed 0\nfullSet, iter: 2 i:76, pairs changed 0\nfullSet, iter: 2 i:77, pairs changed 0\nfullSet, iter: 2 i:78, pairs changed 0\nfullSet, iter: 2 i:79, pairs changed 0\nfullSet, iter: 2 i:80, pairs changed 0\nfullSet, iter: 2 i:81, pairs changed 0\nfullSet, iter: 2 i:82, pairs changed 0\nfullSet, iter: 2 i:83, pairs changed 0\nfullSet, iter: 2 i:84, pairs changed 0\nfullSet, iter: 2 i:85, pairs changed 0\nfullSet, iter: 2 i:86, pairs changed 0\nfullSet, iter: 2 i:87, pairs changed 0\nfullSet, iter: 2 i:88, pairs changed 0\nfullSet, iter: 2 i:89, pairs changed 0\nfullSet, iter: 2 i:90, pairs changed 0\nfullSet, iter: 2 i:91, pairs changed 0\nfullSet, iter: 2 i:92, pairs changed 0\nfullSet, iter: 2 i:93, pairs changed 0\nfullSet, iter: 2 i:94, pairs changed 0\nfullSet, iter: 2 i:95, pairs changed 0\nfullSet, iter: 2 i:96, pairs changed 0\nj not moving enough\nfullSet, iter: 2 i:97, pairs changed 0\nfullSet, iter: 2 i:98, pairs changed 0\nfullSet, iter: 2 i:99, pairs changed 0\niteration number: 3\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "dataArr,labelArr=loadData(\"./testSet.txt\")\n",
    "b,alphas=smoP(dataArr,labelArr,0.6,0.001,40)"
   ]
  },
  {
   "source": [
    "计算得到alpha向量之后，就可以得到超平面(alpha[i]>0.0的第i个数据点构成支持向量)，"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcWs(alphas, dataArr, classLabels):\n",
    "    \"\"\"\n",
    "    基于alpha计算w值\n",
    "    Args:\n",
    "        alphas        拉格朗日乘子\n",
    "        dataArr       feature数据集\n",
    "        classLabels   目标变量数据集\n",
    "    Returns:\n",
    "        wc  回归系数\n",
    "    \"\"\"\n",
    "    X = np.mat(dataArr)\n",
    "    labelMat = np.mat(classLabels).T\n",
    "    m, n = np.shape(X)\n",
    "    w = np.zeros((n, 1))\n",
    "    for i in range(m):\n",
    "        w =w+ np.multiply(alphas[i] * labelMat[i], X[i, :].T)\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "matrix([[ 0.65307162],\n",
       "        [-0.17196128]])"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "ws=calcWs(alphas,dataArr,labelArr)\n",
    "ws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[-0.92555695]]\n-1.0\n"
     ]
    }
   ],
   "source": [
    "# 对第一个数据点分类\n",
    "dataMat=np.mat(dataArr)\n",
    "y=dataMat[0]*np.mat(ws)+b\n",
    "print(y)\n",
    "print(labelArr[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "以下开始，清除所有变量。从新开始\n",
    "\n",
    "## 核函数的SVM\n",
    "\n",
    "以下这些辅助函数不发生变化"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadData(filename):\n",
    "    # 加载数据\n",
    "    dataArr=[];labelArr=[]\n",
    "    fr=open(filename)\n",
    "    for line in fr.readlines():\n",
    "        lineArr=line.strip().split('\\t')\n",
    "        dataArr.append([float(lineArr[0]),float(lineArr[1])])\n",
    "        labelArr.append(float(lineArr[2]))\n",
    "    return dataArr,labelArr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def selectJrand(i,m):\n",
    "    # 第i个alpha的下标，m是alpha的总数\n",
    "    j=i\n",
    "    while (j==i):\n",
    "        j=int(np.random.uniform(0,m))\n",
    "    return j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clipAlpha(alpha,H,L):\n",
    "    # 调整大于或小于alpha的值\n",
    "    if alpha>H:\n",
    "        alpha=H\n",
    "    if alpha<L:\n",
    "        alpha=L\n",
    "    return alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def selectJ(i, oS, Ei):  # this is the second choice -heurstic, and calcs Ej\n",
    "    \"\"\"selectJ（返回最优的j和Ej）\n",
    "    内循环的启发式方法。\n",
    "    选择第二个(内循环)alpha的alpha值\n",
    "    这里的目标是选择合适的第二个alpha值以保证每次优化中采用最大步长。\n",
    "    该函数的误差与第一个alpha值Ei和下标i有关。\n",
    "    Args:\n",
    "        i   具体的第i一行\n",
    "        oS  optStruct对象\n",
    "        Ei  预测结果与真实结果比对，计算误差Ei\n",
    "    Returns:\n",
    "        j  随机选出的第j一行\n",
    "        Ej 预测结果与真实结果比对，计算误差Ej\n",
    "    \"\"\"\n",
    "    maxK = -1\n",
    "    maxDeltaE = 0\n",
    "    Ej = 0\n",
    "    # 首先将输入值Ei在缓存中设置成为有效的。这里的有效意味着它已经计算好了。\n",
    "    oS.cache[i] = [1, Ei]\n",
    "\n",
    "    # print 'oS.eCache[%s]=%s' % (i, oS.eCache[i])\n",
    "    # print 'oS.eCache[:, 0].A=%s' % oS.eCache[:, 0].A.T\n",
    "    # \"\"\"\n",
    "    # # 返回非0的: 行列值\n",
    "    # nonzero(oS.eCache[:, 0].A)= (\n",
    "    #     行:  array([ 0,  2,  4,  5,  8, 10, 17, 18, 20, 21, 23, 25, 26, 29, 30, 39, 46,52, 54, 55, 62, 69, 70, 76, 79, 82, 94, 97]), \n",
    "    #     列:  array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,0, 0, 0, 0, 0])\n",
    "    # )\n",
    "    # \"\"\"\n",
    "    # print 'nonzero(oS.eCache[:, 0].A)=', nonzero(oS.eCache[:, 0].A)\n",
    "    # # 取行的list\n",
    "    # print 'nonzero(oS.eCache[:, 0].A)[0]=', nonzero(oS.eCache[:, 0].A)[0]\n",
    "    # 非零E值的行的list列表，所对应的alpha值\n",
    "    validEcacheList = np.nonzero(oS.cache[:, 0].T)[0]\n",
    "    if (len(validEcacheList)) > 1:\n",
    "        for k in validEcacheList:  # 在所有的值上进行循环，并选择其中使得改变最大的那个值\n",
    "            if k == i:\n",
    "                continue  # don't calc for i, waste of time\n",
    "\n",
    "            # 求 Ek误差: 预测值-真实值的差\n",
    "            Ek = calcEk(oS, k)\n",
    "            deltaE = abs(Ei - Ek)\n",
    "            if (deltaE > maxDeltaE):\n",
    "                maxK = k\n",
    "                maxDeltaE = deltaE\n",
    "                Ej = Ek\n",
    "        return maxK, Ej\n",
    "    else:  # 如果是第一次循环，则随机选择一个alpha值\n",
    "        j = selectJrand(i, oS.m)\n",
    "\n",
    "        # 求 Ek误差: 预测值-真实值的差\n",
    "        Ej = calcEk(oS, j)\n",
    "    return j, Ej"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def updateEk(oS, k):  # after any alpha has changed update the new value in the cache\n",
    "    # 计算误差并存入缓存\n",
    "    \"\"\"updateEk（计算误差值并存入缓存中。）\n",
    "    在对alpha值进行优化之后会用到这个值。\n",
    "    Args:\n",
    "        oS  optStruct对象\n",
    "        k   某一列的行号\n",
    "    \"\"\"\n",
    "    # 求 误差: 预测值-真实值的差\n",
    "    Ek = calcEk(oS, k)\n",
    "    oS.cache[k] = [1, Ek]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smoP(dataMatIn, classLabels, C, toler, maxIter,ktup):\n",
    "    \"\"\"\n",
    "    完整SMO算法外循环，与smoSimple有些类似，但这里的循环退出条件更多一些\n",
    "    Args:\n",
    "        dataMatIn    数据集\n",
    "        classLabels  类别标签\n",
    "        C   松弛变量(常量值)，允许有些数据点可以处于分隔面的错误一侧。\n",
    "            控制最大化间隔和保证大部分的函数间隔小于1.0这两个目标的权重。\n",
    "            可以通过调节该参数达到不同的结果。\n",
    "        toler   容错率\n",
    "        maxIter 退出前最大的循环次数\n",
    "    Returns:\n",
    "        b       模型的常量值\n",
    "        alphas  拉格朗日乘子\n",
    "    \"\"\"\n",
    "\n",
    "    # 创建一个 optStruct 对象\n",
    "    oS = optStruct(np.mat(dataMatIn), np.mat(classLabels).transpose(), C, toler,ktup)\n",
    "    iter = 0\n",
    "    entireSet = True\n",
    "    alphaPairsChanged = 0\n",
    "\n",
    "    # 循环遍历: 循环maxIter次 并且 （alphaPairsChanged存在可以改变 or 所有行遍历一遍）\n",
    "    # 循环迭代结束 或者 循环遍历所有alpha后，alphaPairs还是没变化\n",
    "    while (iter < maxIter) and ((alphaPairsChanged > 0) or (entireSet)):\n",
    "        alphaPairsChanged = 0\n",
    "\n",
    "        #  当entireSet=true or 非边界alpha对没有了；就开始寻找 alpha对，然后决定是否要进行else。\n",
    "        if entireSet:\n",
    "            # 在数据集上遍历所有可能的alpha\n",
    "            for i in range(oS.m):\n",
    "                # 是否存在alpha对，存在就+1\n",
    "                alphaPairsChanged += innerL(i, oS)\n",
    "                # print(\"fullSet, iter: %d i:%d, pairs changed %d\" % (iter, i, alphaPairsChanged))\n",
    "            iter += 1\n",
    "        # 对已存在 alpha对，选出非边界的alpha值，进行优化。\n",
    "        else:\n",
    "            # 遍历所有的非边界alpha值，也就是不在边界0或C上的值。\n",
    "            nonBoundIs = np.nonzero((oS.alphas.T > 0) * (oS.alphas.T < C))[0]\n",
    "            for i in nonBoundIs:\n",
    "                alphaPairsChanged += innerL(i, oS)\n",
    "                # print(\"non-bound, iter: %d i:%d, pairs changed %d\" % (iter, i, alphaPairsChanged))\n",
    "            iter += 1\n",
    "\n",
    "        # 如果找到alpha对，就优化非边界alpha值，否则，就重新进行寻找，如果寻找一遍 遍历所有的行还是没找到，就退出循环。\n",
    "        if entireSet:\n",
    "            entireSet = False  # toggle entire set loop\n",
    "        elif (alphaPairsChanged == 0):\n",
    "            entireSet = True\n",
    "        print(\"iteration number: %d\" % iter)\n",
    "    return oS.b, oS.alphas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcWs(alphas, dataArr, classLabels):\n",
    "    \"\"\"\n",
    "    基于alpha计算w值\n",
    "    Args:\n",
    "        alphas        拉格朗日乘子\n",
    "        dataArr       feature数据集\n",
    "        classLabels   目标变量数据集\n",
    "    Returns:\n",
    "        wc  回归系数\n",
    "    \"\"\"\n",
    "    X = np.mat(dataArr)\n",
    "    labelMat = np.mat(classLabels).T\n",
    "    m, n = np.shape(X)\n",
    "    w = np.zeros((n, 1))\n",
    "    for i in range(m):\n",
    "        w =w+ np.multiply(alphas[i] * labelMat[i], X[i, :].T)\n",
    "    return w"
   ]
  },
  {
   "source": [
    "## 在复杂数据上应用核函数\n",
    "\n",
    "核函数，将数据转换为易于分类器理解的形式。\n",
    "\n",
    "通过核函数，将数据集从一个特征空间映射另一个特征空间。\n",
    "\n",
    "可以将核函数想象为包装器或者接口，它把数据转换为一种容易处理的形式。\n",
    "\n",
    "## 径向基核函数\n",
    "\n",
    "该函数以向量为自变量，计算出一个标量。这里使用径向基函数的高斯版本：\n",
    "\n",
    "$$\n",
    "k(x,y)=exp(\\frac{-||x-y||^2}{2{\\sigma}^2})\n",
    "$$\n",
    "其中，$\\sigma$是用于确定到达率（或函数值跌落带0的速度参数）。\n",
    "\n",
    "高斯核函数将数据映射到更高维的空间。"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kernelTrans(dataArr,dataLine,ktup):\n",
    "    m,n=np.shape(dataArr)\n",
    "    kern=np.zeros((m,1))\n",
    "    if ktup[0]=='lin':\n",
    "        kern=np.dot(dataArr,dataLine.T)\n",
    "    elif ktup[0]=='rbf':\n",
    "        for j in range(m):\n",
    "            dis=dataArr[j,:]-dataLine\n",
    "            kern[j]=np.dot(dis,dis.T)\n",
    "        kern=np.exp(kern/(-1 * ktup[1]**2))\n",
    "    else:\n",
    "        print(\"ktup error\")\n",
    "        return \n",
    "    return kern"
   ]
  },
  {
   "source": [
    "## 将核转换函数，加入到SMO算法中"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "class optStruct:\n",
    "    def __init__(self,dataArr,labelArr,C,toler,ktup):\n",
    "        # 相比无kernel的原SMO，此处多了一个参数\n",
    "        self.dataMat=np.mat(dataArr)\n",
    "        self.labelMat=np.mat(labelArr)\n",
    "        self.C=C\n",
    "        self.tol=toler\n",
    "        self.m,self.n=np.shape(dataArr)\n",
    "        self.alphas=np.zeros((self.m,1))\n",
    "        self.b=0\n",
    "        # 是否有效，实际的E值\n",
    "        self.cache=np.zeros((self.m,2))\n",
    "        # 新增\n",
    "        self.K=np.zeros( (self.m,self.m) )\n",
    "        for i in range(self.m):\n",
    "            self.K[:,i]=kernelTrans(self.dataMat,self.dataMat[i,:],ktup).reshape(self.m)"
   ]
  },
  {
   "source": [
    "加入核函数之后，innerL函数和calcEK函数需要做一些修改"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def innerL(i, oS):\n",
    "    \"\"\"innerL\n",
    "    内循环代码\n",
    "    Args:\n",
    "        i   具体的某一行\n",
    "        oS  optStruct对象\n",
    "    Returns:\n",
    "        0   找不到最优的值\n",
    "        1   找到了最优的值，并且oS.Cache到缓存中\n",
    "    \"\"\"\n",
    "\n",
    "    # 求 Ek误差: 预测值-真实值的差\n",
    "    Ei = calcEk(oS, i)\n",
    "\n",
    "    if ((oS.labelMat[i] * Ei < -oS.tol) and (oS.alphas[i] < oS.C)) or ((oS.labelMat[i] * Ei > oS.tol) and (oS.alphas[i] > 0)):\n",
    "        # 选择最大的误差对应的j进行优化。效果更明显\n",
    "        j, Ej = selectJ(i, oS, Ei)\n",
    "        alphaIold = oS.alphas[i].copy()\n",
    "        alphaJold = oS.alphas[j].copy()\n",
    "\n",
    "        # L和H用于将alphas[j]调整到0-C之间。如果L==H，就不做任何改变，直接return 0\n",
    "        if (oS.labelMat[i] != oS.labelMat[j]):\n",
    "            L = max(0, oS.alphas[j] - oS.alphas[i])\n",
    "            H = min(oS.C, oS.C + oS.alphas[j] - oS.alphas[i])\n",
    "        else:\n",
    "            L = max(0, oS.alphas[j] + oS.alphas[i] - oS.C)\n",
    "            H = min(oS.C, oS.alphas[j] + oS.alphas[i])\n",
    "        if L == H:\n",
    "            return 0\n",
    "\n",
    "        # eta是alphas[j]的最优修改量，如果eta==0，需要退出for循环的当前迭代过程\n",
    "        # 修改\n",
    "        eta = 2.0 * oS.K[i,j] * oS.K[i, i] - oS.K[j,j]\n",
    "\n",
    "        if eta >= 0:\n",
    "            return 0\n",
    "\n",
    "        # 计算出一个新的alphas[j]值\n",
    "        oS.alphas[j] =oS.alphas[j]- oS.labelMat[j] * (Ei - Ej) / eta\n",
    "        # 并使用辅助函数，以及L和H对其进行调整\n",
    "        oS.alphas[j] = clipAlpha(oS.alphas[j], H, L)\n",
    "        # 更新误差缓存\n",
    "        updateEk(oS, j)\n",
    "\n",
    "        # 检查alpha[j]是否只是轻微的改变，如果是的话，就退出for循环。\n",
    "        if (abs(oS.alphas[j] - alphaJold) < 0.00001):\n",
    "            return 0\n",
    "\n",
    "        # 然后alphas[i]和alphas[j]同样进行改变，虽然改变的大小一样，但是改变的方向正好相反\n",
    "        oS.alphas[i] =oS.alphas[i] + oS.labelMat[j] * oS.labelMat[i] * (alphaJold - oS.alphas[j])\n",
    "        # 更新误差缓存\n",
    "        updateEk(oS, i)\n",
    "\n",
    "        # 在对alpha[i], alpha[j] 进行优化之后，给这两个alpha值设置一个常数b。\n",
    "        # 修改\n",
    "        b1 = oS.b - Ei - oS.labelMat[i] * (oS.alphas[i] - alphaIold) * oS.K[i,i] - oS.labelMat[j] * (oS.alphas[j] - alphaJold) * oS.K[i,j]\n",
    "        b2 = oS.b - Ej - oS.labelMat[i] * (oS.alphas[i] - alphaIold) * oS.K[i,j]- oS.labelMat[j] * (oS.alphas[j] - alphaJold) * oS.K[j,j]\n",
    "        if (0 < oS.alphas[i]) and (oS.C > oS.alphas[i]):\n",
    "            oS.b = b1\n",
    "        elif (0 < oS.alphas[j]) and (oS.C > oS.alphas[j]):\n",
    "            oS.b = b2\n",
    "        else:\n",
    "            oS.b = (b1 + b2) / 2.0\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcEk(oS:optStruct,i:int):\n",
    "    # 给定alpha下计算E\n",
    "    # W^T\n",
    "    W=np.multiply(oS.alphas,oS.labelMat)\n",
    "    # m*1\n",
    "    # Xi=np.multiply(dataMat,dataMat[i,:].T)\n",
    "    Xi=oS.K[:,i]\n",
    "    # 预测值 1*1\n",
    "    fxi=np.dot(W.T,Xi)+oS.b\n",
    "    # 计算误差\n",
    "    Ei=fxi-float(oS.labelMat[i])\n",
    "    # 返回误差\n",
    "    return Ei"
   ]
  },
  {
   "source": [
    "测试 "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# test\n",
    "dataArr,labelArr=loadData(\"./testSet.txt\")\n",
    "b,alphas=smoP(dataArr,labelArr,200,0.0001,10000,('rbf',1.3))"
   ],
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   }
  },
  {
   "source": [],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelTest():\n",
    "    dataArr,labelArr=loadData(\"./testSetRBF.txt\")\n",
    "    b,alphas=smoP(dataArr,labelArr,200,0.0001,10000,('rbf',1.3))\n",
    "    dataMat=np.mat(dataArr);labelMat=np.mat(labelArr).T\n",
    "    svIndex=np.nonzero(alphas)[0]\n",
    "    svS=dataMat[svIndex]\n",
    "    labelSv=labelMat[svIndex]\n",
    "    m,n=np.shape(dataMat)\n",
    "    errCnt=0\n",
    "    for i in range(m):\n",
    "        kern=kernelTrans(svS,dataMat[i,:],('rbf',1.3))\n",
    "        predict=np.dot(kern.T,np.multiply(labelSv,alphas[svIndex]))+b\n",
    "        if np.sign(predict)!=np.sign(labelArr[i]):\n",
    "            errCnt+=1\n",
    "    return 1-errCnt/float(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "iteration number: 1\n",
      "iteration number: 2\n",
      "iteration number: 3\n",
      "iteration number: 4\n",
      "iteration number: 5\n",
      "iteration number: 6\n",
      "iteration number: 7\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.6599999999999999"
      ]
     },
     "metadata": {},
     "execution_count": 74
    }
   ],
   "source": [
    "modelTest()"
   ]
  },
  {
   "source": [
    "正确率相差太大，貌似那里出了bug。\n",
    "\n",
    "先跳过了。"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}